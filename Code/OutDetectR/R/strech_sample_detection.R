#' Performs the full stretching and sampling procedure on a data set.
#'
#' @param cl: cluster object generated by parallel package
#' @param list_path: path to the random access list of the data set (generated by package largeList)
#' this assumes that all observations are already zeroed and for every observation
#' there are more comparable counterparts than the parameter sample_size
#' @param lambda: allowed stretching parameter
#' @param n_samples: number of samples to use
#' @param sample_size: number of observations to use in each sample
#' @param expn: Chosen expected number of draws any observation appears in per
#' unique interval it is comparable to.
#' @param alpha: quantile of least deep observations to drop before bootstrapping
#' (in approximation of C)
#' @param B: number of smoothed bootstrap samples to use (in approximation of C)
#' @param gamma: tuning parameter for smoothed bootstrap
#' @param debug: choose whether text outputs are given
#'
#' @return A list containing three elements:
#' num_samples: The number of samples each observation was part of (vector)
#' num_outliers: The number of samples each observation was classified as an outlier in (vector)
#' certainties: The quotient of num_outliers and num_samples (so the relative frequency of 
#' observations being classified as outliers)
#' @export
stretch_sample_detection <- function(cl, list_path, lambda, measuring_intervals,
                                     n_samples = NULL, sample_size, expn = NULL,
                                     alpha, B, gamma, debug = FALSE) {
  # Set up boolean for later
  if (missing(n_samples)) {
    n_sample_bool <- FALSE
  } else {
    n_sample_bool <- TRUE
  }

  # get number of observations in list
  n_obs <- getListLength(file = list_path)
  tmp_ids <- 1:n_obs

  # find unique measuring intervals
  unique_intervals <- unique_intervals(interval_matrix = measuring_intervals)
  n_unique_int <- dim(unique_intervals)[1]

  if (debug) {
    print(paste0("There are ", n_unique_int, " unique measuring intervals."))
  }

  # create vectors as described in the description part
  num_samples <- rep(x = 0, times = n_obs)
  num_outliers <- rep(x = 0, times = n_obs)
  frac_outliers <- rep(x = 1, times = n_obs)

  # iteration process
  for (i in 1:n_unique_int) {
    current_interval <- unique_intervals[i, ]

    # set fail counter to 0 update with try catch procedure
    fail_counter <- 0

    # print out current measuring interval
    if (debug) {
      print(paste0("Interval ", i, " out of ", n_unique_int))
      print(paste0("Current Interval: ", current_interval[1], " to ", current_interval[2]))
    }

    # find comparable observations
    comparable <- comparable_obs_finder(
      main_interval = unique_intervals[i, ],
      measuring_intervals = measuring_intervals,
      lambda = lambda, ids = tmp_ids
    )$ind

    # find number of comparable observations
    n_comparables <- length(comparable)

    # determine n_samples dynamically
    if (n_sample_bool == FALSE) {
      if (missing(expn)) {
        stop("Either n_samples or expn has to be provided.")
      } else {
        n_samples <- sampling_number(
          n_comparables = n_comparables,
          sample_size = sample_size,
          expn = expn
        )
      }
    }

    # print out number of comparables and chosen number of samples
    if (debug) {
      print(paste0("Number of comparable observations: ", n_comparables))
      print(paste0("Number of samples: ", n_samples))
    }

    # switch cases if sample_size > n_comparables
    if (n_comparables > sample_size) {

      # use stretching and sampling procedure for those comparable sets
      tmp_sample_res <- stretch_sample_wrap(
        cl = cl, list_path = list_path, main_interval = current_interval,
        indeces = comparable, n_samples = n_samples, sample_size = sample_size,
        alpha = alpha, B = B, gamma = gamma
      )

      # update the vectors
      num_samples[comparable] <- num_samples[comparable] + tmp_sample_res$num_samples
      num_outliers[comparable] <- num_outliers[comparable] + tmp_sample_res$num_outliers
    } else {

      # determine factor for num_samples and num_outliers
      if (missing(expn)) {
        tmp_factor <- sampling_factor(
          n_comparables = n_comparables, sample_size = sample_size, n_samples = n_samples
        )
      } else {
        tmp_factor <- expn
      }

      if (n_comparables == 1) {
        # if no other comparable observation exists classify
        # observation as outlier
        num_samples[comparable] <- num_samples[comparable] + tmp_factor
        num_outliers[comparable] <- num_outliers[comparable] + tmp_factor
      } else {
        # load data from large list
        tmp_dat <- readList(file = list_path, index = comparable)

        # stretch data to main interval
        tmp_stretch <- stretch_data(
          func_dat = tmp_dat, measuring_interval = current_interval
        )

        # use detection procedure to identify outliers
        tmp_res <- detection_wrap(
          func_dat = tmp_stretch, ids = comparable,
          alpha = alpha, B = B, gamma = gamma
        )$outlier_ids

        # update vectors accordingly
        num_samples[comparable] <- num_samples[comparable] + tmp_factor
        num_outliers[tmp_res] <- num_outliers[tmp_res] + tmp_factor
      }
    }
  }

  # calculate the relative frequency of outliers
  frac_outliers <- unlist(map(
    .x = 1:n_obs,
    .f = function(i) ifelse(num_samples[i] != 0, num_outliers[i] / num_samples[i], 1)
  ))

  # Return the three vectors
  return(list(
    num_samples = num_samples,
    num_outliers = num_outliers,
    certainties = frac_outliers
  ))
}
