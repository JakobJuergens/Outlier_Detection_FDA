#' placeholder
#'
#' @param cl: cluster object generated by parallel package
#' @param list_path: path to the random access list of the data set (generated by package largeList)
#' this assumes that all observations are already zeroed and for every observation
#' there are more comparable counterparts than the parameter sample_size
#' @param lambda: allowed stretching parameter
#' @param n_samples: number of samples to use
#' @param sample_size: number of observations to use in each sample
#' @param expn: Chosen expected number of draws any observation appears in per
#' unique interval it is comparable to.
#' @param alpha: quantile of least deep observations to drop before bootstrapping
#' (in approximation of C)
#' @param B: number of smoothed bootstrap samples to use (in approximation of C)
#' @param gamma: tuning parameter for smoothed bootstrap
#' @param debug: choose whether text outputs are given
#'
#' @return placeholder
#' @export
stretch_sample_detection <- function(cl, list_path, lambda, measuring_intervals,
                                     n_samples = NULL, sample_size, expn = NULL,
                                     alpha, B, gamma, debug = FALSE) {
  # get number of observations in list
  n_obs <- getListLength(file = list_path)
  tmp_ids <- 1:n_obs

  # find unique measuring intervals
  unique_intervals <- unique_intervals(interval_matrix = measuring_intervals)
  n_unique_int <- dim(unique_intervals)[1]

  if (debug) {
    print(paste0("There are ", n_unique_int, " unique measuring intervals."))
  }

  # create vectors as described in the description part
  num_samples <- rep(x = 0, times = n_obs)
  num_outliers <- rep(x = 0, times = n_obs)
  frac_outliers <- rep(x = 1, times = n_obs)

  # iteration process
  for (i in 1:n_unique_int) {
    current_interval <- unique_intervals[i, ]

    # print out current measuring interval
    if (debug) {
      print(paste0("Interval ", i, " out of ", n_unique_int))
      print(paste0("Current Interval: ", current_interval[1], " to ", current_interval[2]))
    }

    # find comparable observations
    comparable <- comparable_obs_finder(
      main_interval = unique_intervals[i, ],
      measuring_intervals = measuring_intervals,
      lambda = lambda, ids = tmp_ids
    )$ind

    # find number of comparable observations
    n_comparables <- length(comparable)

    # determine n_samples dynamically
    if (missing(n_samples)) {
      if (missing(expn)) {
        stop("Either n_samples or expn has to be provided.")
      } else {
        n_samples <- sampling_number(
          n_comparables = n_comparables,
          sample_size = sample_size,
          expn = expn
        )
      }
    }

    # print out number of comparables
    if (debug) {
      print(paste0("Number of comparable observations: ", n_comparables))
    }

    # switch cases if sample_size > n_comparables
    if (n_comparables > sample_size) {

      # use stretching and sampling procedure for those comparable sets
      tmp_sample_res <- stretch_sample_wrap(
        cl = cl, list_path = list_path, main_interval = current_interval,
        indeces = comparable, n_samples = n_samples, sample_size = sample_size,
        alpha = alpha, B = B, gamma = gamma
      )
      
      # print number of outliers found in iteration
      if (debug) {
        print(paste0("Number of outliers: ", length(which(tmp_sample_res$num_outliers != 0))))
      }
      
      # update the vectors
      num_samples[comparable] <- num_samples[comparable] + tmp_sample_res$num_samples
      num_outliers[comparable] <- num_outliers[comparable] + tmp_sample_res$num_outliers
    } else {

      # determine factor for num_samples and num_outliers
      if (missing(expn)) {
        tmp_factor <- sampling_factor(
          n_comparables = n_comparables, sample_size = sample_size, n_samples = n_samples
        )
      } else {
        tmp_factor <- expn
      }

      # load data from large list
      tmp_dat <- readList(file = list_path, index = comparable)

      # stretch data to main interval
      tmp_stretch <- stretch_data(
        func_dat = tmp_dat, measuring_interval = current_interval
      )

      # determine grid for approximation
      tmp_grid <- grid_finder(func_dat = tmp_stretch)

      # perform grid approximation and transformation to matrix
      tmp_grid_dat <- grid_approx_mat(func_dat = tmp_stretch, grid = tmp_grid)

      # use detection procedure to identify outliers
      tmp_res <- outlier_detection(
        matr_dat = tmp_grid_dat, alpha = alpha,
        B = B, gamma = gamma, ids = comparable, # is comparable right here?
        grid = tmp_grid
      )$outlier_ids

      # print number of outliers found in iteration
      if (debug) {
        print(paste0("Number of outliers: ", length(tmp_res)))
      }
      
      # update vectors accordingly
      num_samples[comparable] <- num_samples[comparable] + tmp_factor
      num_outliers[tmp_res] <- num_outliers[tmp_res] + tmp_factor
    }

    # manually run gc() as there seems to be a problem with memory usage
    # rm(tmp_sample_res, comparable)
    # gc()
  }

  # calculate the relative frequency of outliers
  frac_outliers <- unlist(map(
    .x = 1:n_obs,
    .f = function(i) ifelse(num_samples[i] != 0, num_outliers[i] / num_samples[i], 1)
  ))

  # Return the three vectors
  return(list(
    num_samples = num_samples,
    num_outliers = num_outliers,
    certainties = frac_outliers
  ))
}
