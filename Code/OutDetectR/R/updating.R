#' Placeholder
#'
#' @param func_obs: list with two elements: vectors of equal length called args and vals
#' @param unique_intervals: matrix containing measuring intervals that occur in the data set (one in each row)
#' @param lambda: acceptable stretching parameter

possible_occurences <- function(func_obs, unique_intervals, lambda) {

  # determine measuring interval of new observation
  new_measuring_interval <- c(min(func_obs$args), max(func_obs$args))

  # determine for all previously used measuring intervals if the new
  # observation could have been part of the stretching and sampling procedure
  occurs <- unlist(map(
    .x = 1:(dim(unique_intervals)[1]),
    .f = function(i) {
      ifelse((new_measuring_interval[2] >= unique_intervals[i, 2] / lambda) &
        (new_measuring_interval[2] <= unique_intervals[i, 2] * lambda),
      TRUE, FALSE
      )
    }
  ))

  # return the indices and intervals that the new observation could have been a part of
  return(list(
    occurs = occurs,
    occurs_intervals = unique_intervals[occurs, ]
  ))
}

#' placeholder
#'
#' @param list_path: path to the random access list of the data set (generated by package largeList)
#' @param new_observation: new observations added to the data set
#' @param new_id: identifier for the new observations added to the data set
#' @param main_interval: Measuring interval currently under consideration
#' @param index: index of observations to use in the procedure
#' (decided to be comparable in the calling function)
#' @param alpha: quantile of least deep observations to drop before bootstrapping (in approximation of C)
#' @param B: number of smoothed bootstrap samples to use (in approximation of C)
#' @param gamma: tuning parameter for smoothed bootstrap
#'
#' @return placeholder
stsa_update_helper <- function(list_path, new_observation, new_id, main_interval,
                               ids, index, alpha, B, gamma) {

  # read in the observations identified by the variable index
  sample_dat <- readList(file = list_path, index = index)

  # add new observation to sample_dat
  sample_dat <- c(sample_dat, list(new_observation))

  # add new observation to ids
  ids <- c(ids, new_id)

  # stretch observations to the chosen measuring interval
  sample_dat_stretched <- stretch_data(
    func_dat = sample_dat, measuring_interval = main_interval
  )

  # perform the outlier detection procedure on the sample
  # in a tryCatch statement as the procedure creates notamatrix errors in random cases
  sample_flagged <- tryCatch(
    {
      detection_wrap(
        func_dat = sample_dat, ids = ids,
        alpha = alpha, B = B, gamma = gamma
      )$outlier_ids
    },
    error = function(cond) {
      return(list(outlier_ids = c(), outlier_ind = c()))
    }
  )
  
  # return the object generated by the outlier detection procedure
  return(sample_flagged)
}

#' placeholder
#'
#' @param cl: cluster object generated by parallel package
#' @param new_observation: new observations added to the data set
#' @param list_path: path to the random access list of the data set (generated by package largeList)
#' @param main_interval: measuring interval the observations are stretched to
#' @param indices: Vector containing the indeces of observations that are
#' included in the sampling procedure
#' @param n_samples: number of samples to use
#' @param sample_size: number of observations to use in each sample
#' @param alpha: quantile of least deep observations to drop before bootstrapping
#' (in approximation of C)
#' @param B: number of smoothed bootstrap samples to use (in approximation of C)
#' @param gamma: tuning parameter for smoothed bootstrap
#'
#' @return placeholder
#' @export
stsa_update_wrap <- function(cl, new_observation, list_path, main_interval,
                             indeces = NULL, n_samples, sample_size, alpha, B, gamma) {

  # get number of observations from the largeList file if indices is missing
  # Assumption: if no indices are given, all observations are being considered
  if (missing(indeces)) {
    indices <- 1:largeList::getListLength(list_path)
  }

  # add one for the new observation
  n_obs <- length(indeces) + 1
  tmp_ids <- 1:n_obs

  # Initialize vectors described in the theoretical section
  num_samples <- rep(x = 0, times = n_obs)
  num_outliers <- rep(x = 0, times = n_obs)
  frac_outliers <- rep(x = 1, times = n_obs)

  # Draw indexes for sampling from functional data without replacement
  # add n_obs to all samples for the new observation
  sample_inds <- map(
    .x = 1:n_samples,
    .f = function(i) c(sample(x = tmp_ids[-n_obs], size = sample_size - 1, replace = FALSE))
  )

  # Determine how often each observation appeared in the samples and update the vector
  freq_samples <- tabulate(as.numeric(unlist(sample_inds)))
  num_samples[1:length(freq_samples)] <- num_samples[1:length(freq_samples)] + freq_samples
  num_samples[length(num_samples)] <- num_samples[length(num_samples)] + n_samples
  
  # Perform the outlier classification procedure on the chosen samples parallelized
  # with the function clusterApplyLB() from the parallel package
  sample_flagged_par <- clusterApplyLB(
    cl = cl,
    x = sample_inds,
    fun = function(smpl) {
      stsa_update_helper(
        list_path = list_path, new_observation = new_observation, new_id = n_obs,
        main_interval = main_interval, ids = tmp_ids[smpl],
        index = indeces[smpl], alpha = alpha, B = B, gamma = gamma
      )
    }
  )

  # Determine how often each observation were flagged in the samples and update the vector
  # this check is a hack. Should be solved differently in the future
  if (length(sample_flagged_par) != 0) {
    freq_outliers <- tabulate(as.numeric(unlist(sample_flagged_par)))
    num_outliers[1:length(freq_outliers)] <- num_outliers[1:length(freq_outliers)] + freq_outliers
  }

  # determine fraction of samples each observation was flagged as an outlier in
  certainties <- unlist(map(
    .x = 1:n_obs,
    .f = function(i) ifelse(num_samples[i] != 0, num_outliers[i] / num_samples[i], 1)
  ))

  # Return list containing the three central vectors: num_samples, num_outliers, certainties
  return(list(
    num_samples = num_samples,
    num_outliers = num_outliers,
    certainties = certainties
  ))
}

#' placeholder
#'
#' @param cl: cluster object generated by parallel package
#' @param new_observation: new observations added to the data set
#' @param list_path: path to the random access list of the data set (generated by package largeList)
#' this assumes that all observations are already zeroed and for every observation
#' there are more comparable counterparts than the parameter sample_size
#' @param lambda: allowed stretching parameter
#' @param n_samples: number of samples to use
#' @param sample_size: number of observations to use in each sample
#' @param expn: Chosen expected number of draws any observation appears in per
#' unique interval it is comparable to.
#' @param alpha: quantile of least deep observations to drop before bootstrapping
#' (in approximation of C)
#' @param B: number of smoothed bootstrap samples to use (in approximation of C)
#' @param gamma: tuning parameter for smoothed bootstrap
#' @param num_samples_prev: value of num_samples before new observation was added
#' @param num_outliers_prev: value of num_outliers before new observation was added
#' @param debug: choose whether text outputs are given
#'
#' @return placeholder
#' @export
stretch_sample_updating <- function(cl, new_observation, list_path, lambda, measuring_intervals,
                                    sample_size, expn, alpha, B, gamma, num_samples_prev, num_outliers_prev,
                                    debug = FALSE) {

  # get number of observations in list
  n_obs <- getListLength(file = list_path)
  tmp_ids <- 1:(n_obs + 1)

  # find unique measuring intervals
  unique_intervals <- unique_intervals(interval_matrix = measuring_intervals)

  # find measuring intervals the new observation could have appeared in
  # during the sampling process
  occurs <- possible_occurences(
    func_obs = new_observation, unique_intervals = unique_intervals, lambda = lambda
  )$occurs

  # Include case if there are no comparable intervals
  if(length(occurs) == 0){
    # in this case there are no other observations with a comparable 
    # measuring interval
    
    # create output vectors
    num_samples <- c(num_samples_prev, 0)
    num_outliers <- c(num_outliers_prev, 0)
    frac_outliers <- c((num_outliers_prev / num_samples_prev), 1)
    
    return(list(
      num_samples = num_samples,
      num_outliers = num_outliers,
      certainties = frac_outliers
    ))
  }
  
  # create matrix of comparable intervals
  unique_possible_intervals = unique_intervals[occurs, ]
  
  # find number of possible intervals
  n_unique_int <- dim(unique_possible_intervals)[1]

  if (debug) {
    print(
      paste0(
        "There are ", n_unique_int,
        " unique measuring intervals in which the new observations",
        " could occur in for the chosen lambda."
      )
    )
  }

  # create vectors as described in the description part
  num_samples <- c(num_samples_prev, 0)
  num_outliers <- c(num_outliers_prev, 0)
  frac_outliers <- rep(x = 1, times = n_obs + 1)

  # iteration process ### This is still copied from the stretch_sample file
  # has to be adjusted for updating procedure
  for (i in 1:n_unique_int) {
    current_interval <- unique_possible_intervals[i, ]

    # set fail counter to 0 update with try catch procedure
    fail_counter <- 0

    # print out current measuring interval
    if (debug) {
      print(paste0("Interval ", i, " out of ", n_unique_int))
      print(paste0("Current Interval: ", current_interval[1], " to ", current_interval[2]))
    }

    # find comparable observations
    comparable <- comparable_obs_finder(
      main_interval = current_interval, measuring_intervals = measuring_intervals,
      lambda = lambda, ids = tmp_ids
    )$ind

    # find number of comparable observations (+1 adjustment for new observation)
    n_comparables <- length(comparable) + 1

    # determine n_samples dynamically
    n_samples <- expn

    # print out number of comparables and chosen number of samples
    if (debug) {
      print(paste0("Number of comparable observations: ", n_comparables))
      print(paste0("Number of samples: ", n_samples))
    }

    # switch cases if sample_size > n_comparables
    if (n_comparables > sample_size) {

      # use stretching and sampling procedure for those comparable sets
      tmp_sample_res <- stsa_update_wrap(
        cl = cl, list_path = list_path, new_observation = new_observation,
        main_interval = current_interval, indeces = comparable,
        n_samples = n_samples, sample_size = sample_size, alpha = alpha,
        B = B, gamma = gamma
      )

      # update the vectors
      num_samples[c(comparable, length(num_samples))] <- num_samples[c(comparable, length(num_samples))] + tmp_sample_res$num_samples
      num_outliers[c(comparable, length(num_samples))] <- num_outliers[c(comparable, length(num_samples))] + tmp_sample_res$num_outliers
    } else {
      tmp_factor <- expn

      if (n_comparables == 1) {
        # if no other comparable observation exists classify
        # observation as outlier
        num_samples[c(comparable, length(num_samples))] <- num_samples[c(comparable, length(num_samples))] + tmp_factor
        num_outliers[c(comparable, length(num_samples))] <- num_outliers[c(comparable, length(num_samples))] + tmp_factor
      } else {
        # load data from large list
        tmp_dat <- readList(file = list_path, index = comparable)
        tmp_dat <- c(tmp_dat, new_observation)

        # stretch data to main interval
        tmp_stretch <- stretch_data(
          func_dat = tmp_dat, measuring_interval = current_interval
        )

        # use detection procedure to identify outliers
        tmp_res <- detection_wrap(
          func_dat = tmp_stretch, ids = c(comparable, length(num_samples)),
          alpha = alpha, B = B, gamma = gamma
        )$outlier_ids

        # update vectors accordingly
        num_samples[c(comparable, length(num_samples))] <- num_samples[c(comparable, length(num_samples))] + tmp_factor
        num_outliers[tmp_res] <- num_outliers[tmp_res] + tmp_factor
      }
    }
  }

  # calculate the relative frequency of outliers
  frac_outliers <- unlist(map(
    .x = 1:(n_obs + 1),
    .f = function(i) ifelse(num_samples[i] != 0, num_outliers[i] / num_samples[i], 1)
  ))

  # Return the three vectors
  return(list(
    num_samples = num_samples,
    num_outliers = num_outliers,
    certainties = frac_outliers
  ))
}
